{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biol 359A | Data, distributions, variance, and correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spring 2024, Week 1\n",
    "Objectives:\n",
    "- Gain familiarity with fundamental concepts in python programming and Jupyter Notebooks\n",
    "- Gain intuition for how parameter changes affect distribution shapes for common distributions\n",
    "- Gain intuition for Pearson's coorelation and Spearman's coorelation\n",
    "- Enjoy thinking about penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin by meeting your group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please introduce yourself to your breakout group and share one of your favorite foods\n",
    "\n",
    "ASSIGNMENT QUESTIONS:\n",
    "- Please complete question 16 in th. assignment on canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a best practice in python to import the packages you use in each file near or at the top of the file. Here are import statements for the packages we will use throughout the rest of this notebook.\n",
    "\n",
    "The packages used are as follows\n",
    "- `pandas` provides dataframes for data storage and manipulation\n",
    "- `ipywidgets` provides dynamic notebook widgets (like sliders)\n",
    "- `scipy` us a general scientific computing package\n",
    "- `numpy` is a general math/matrices package\n",
    "- `matplotlib` Provides data visualization functionality\n",
    "\n",
    "Using \"as\" creates an alias or alternate name for packages. Some packages have commonly used aliases as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 1 contains a very broad overview of jupyter notebooks, programming concepts, and python programming concepts more specifically. It is not meant to be comprehensive, but to introduce some fundamental ideas about programming and programming specifically in Python. It is here for your reference. There are no questions in section 1 and it may be skipped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in Jupyter Notebooks you can collapse sections by clicking the arrow to the left of headers. Try collapsing Section 1 now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All coding in this course will be completed in Jupyter Notebooks (like this one!). Jupyter Notebooks present runable code cells alongside markdown cells. You can run the code cells by holding `shift` and hitting `enter`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Introduction to python programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jupyter Notebooks\n",
    "\n",
    "As stated above, Jupyter Notebooks present runable code cells alongside markdown cells. You can run the code cells by holding `shift` and hitting `enter`. Run the two code cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_variable = \"I am a variable!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_variable # This will print the value of a_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IT IS VERY IMPORTANT TO NOTE:** that the order in which you execute code in a Jupyter Notebook is EXTREMELY IMPORTANT. For instance, run the code in the cell below this markdown cell, and then the cell immediately above this markdown cell. The value of `a_variable` will be determined by the latest cell you've run, not necessarily the cell physically located above it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_variable = \"I am not a variable!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the hardware level, computers store all their data using the binary system, which means that every piece of information is represented as a series of 0s and 1s. This includes numbers, letters, and everything else we see on a screen. However, the same series of 0s and 1s can have different meanings. For example, the 8-bit binary sequence \"01000001\" is the binary code for both number 65 and the letter A.\n",
    "\n",
    "Given that everything is stored in these binary sequences, how does a computer know if the series \"01000001\" stored in memory should be interpreted as a number, a letter, or something else?\n",
    "\n",
    "Data types solve this problem. They tell the computer the type of data a binary sequence represents, ensuring it translates and treats the data appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The print() function is used to output data to the console. In Jupyter Notebooks, the last line of a cell is automatically printed.\n",
    "# Here we use print() statements to output all lines of the cell\n",
    "print(1)\n",
    "print(1 + 1)\n",
    "print('A')\n",
    "print('A' + 'A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, the behavior of the + operator is different depending on what it is between. When between two `1`s, it performed addition, but when between two `A`'s, it performed [concatonation](https://www.merriam-webster.com/dictionary/concatenate#h2). This is because `1` and `A` are different data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The type() function returns the data type of the data it receives as an argument.\n",
    "print(type(1))\n",
    "print(type('A'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that `1` is of type 'int', or integer, and `A` is of type 'str', or string. These are two common data types. Integers are whole numbers and strings are letters, words, and number that are meant to be read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(\"This is a string\"))\n",
    "print(type(\"I can write 2 strings\")) # Even though this string contains an integer, it is still a string.\n",
    "print(type('1')) # Because this is wrapped in quotes, this is a string, not an integer.\n",
    "print('1' + '1') # This will output 11, because the 1's are strings, not integers, and the + operator concatonates strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are some other common datatypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(1.0)) # Floats are numbers with decimal points.\n",
    "print(type(True)) # Booleans are either True or False.\n",
    "print(type(None)) # None represents the absence of a value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables\n",
    "\n",
    "Variables hold a piece of data or a value and allow you to reference it by a name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 2 # length is a variable. Variables are used to store data that can be used later in the program.\n",
    "width = 3 # width is another variable.\n",
    "area = length * width # area is a third variable. It is the product of the length and width variables.\n",
    "area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables promote code flexibility and readability. We will use them extensively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Structures\n",
    "\n",
    "You can think of data structures as containers that hold data or variables. Python has some built-in data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type([1, 2, 3])) # Lists allow you to keep items in a specific order and allow you to add and remove items.\n",
    "print(type((1, 2, 3))) # Tuples are similar to lists, but they are immutable, meaning you cannot change them by adding or removing items.\n",
    "print(type({1: \"one\", 2: \"two\", 3: \"three\"})) # Dictionaries are used to store key-value pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use data structures to store other data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type([[1, 2, 3], [\"a\", \"b\", \"c\"], [1.0, 2.0, 3.0]])) # This is a list of lists.\n",
    "print(type((1, [1, 2, 3], \"A\"))) # This is a tuple containing an integer, a list, and a string.\n",
    "print(type({\"A\": [1, 2, 3], \"B\": [\"a\", \"b\", \"c\"], \"C\": [1.0, 2.0, 3.0]})) # This is a dictionary containing lists as values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has a large library of packages, or collections of code written by other organizations or individuals, that you can use. A frequently used package in data analysis is pandas. Pandas gives you access to a data structure called a dataframe, which is essentially a matrix for storing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas # This imports the pandas package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame({\"A\": [1, 2, 3], \"B\": [\"A\", \"B\", \"C\"], \"C\": [1.0, 2.0, 3.0]}) # This creates a pandas DataFrame.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use pandas dataframes extensively in this course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions are used to perform specific tasks. They can take arguments as input and return values. Here is an example of a function that takes two arguments and returns their sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sum(a, b): # This is a function that takes two arguments and returns their sum.\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(find_sum(1, 2))\n",
    "print(find_sum(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions allow you to perform a task many times without rewriting code. They make code more readable and enable repetetive tasks to be solved efficiently. Many functions have been defined in python packages. We will be using functions extensively throughout this course. \n",
    "\n",
    "In fact, we have already used several functions in this notebook! For example, the `print()` function prints its argument, the `type()` function returns the type of its argument, and the `pandas.DataFrame()` (which is defined in the pandas package) makes a new DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Statistical concepts review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains some definitions and example calculations of statistical measures. We will use synthetic data relating to rolling a fair 6-sided die to illustrate each concept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition**: The expected value of a random variable is a measure of the central tendency. It is calculated as the weighted average of all possible values. For discrete variables, it's the sum of the product of each value and its probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Expected value of a fair die roll\n",
    "values = np.array([1, 2, 3, 4, 5, 6])\n",
    "probabilities = np.repeat(1/6, 6)  # Equal probability for a fair die\n",
    "expected_value = np.sum(values * probabilities)\n",
    "print(f\"Expected Value: {expected_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition**: The sample mean is the average value of a sample and is a practical estimate of the population mean or expected value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Sample mean from random die rolls\n",
    "sample = np.random.choice(values, size=100, p=probabilities)\n",
    "sample_mean = np.mean(sample)\n",
    "print(f\"Sample Mean: {sample_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the sample mean always equal to the expected value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a plot of sample means with different sample sizes. The red horizontal line is the expected value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a fair die\n",
    "values = np.array([1, 2, 3, 4, 5, 6])\n",
    "probabilities = np.repeat(1/6, 6)\n",
    "\n",
    "# Expected value\n",
    "expected_value = np.sum(values * probabilities)\n",
    "\n",
    "# Generate samples of different sizes and calculate their means\n",
    "sample_sizes = [10, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "sample_means = [np.mean(np.random.choice(values, size=s, p=probabilities)) for s in sample_sizes]\n",
    "\n",
    "# Plot\n",
    "plt.axhline(y=expected_value, color='r', linestyle='-', label='Expected Value')\n",
    "plt.scatter(sample_sizes, sample_means, color='blue', label='Sample Mean')\n",
    "plt.legend()\n",
    "plt.xlabel('Sample Size')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Expected Value vs. Sample Mean')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCUSSION QUESTION:\n",
    "1. How does the sample mean compare to the expected value as sample size increases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition**: Variance measures the dispersion of a set of data points around their mean value. It's defined as the average of the squared differences from the Mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Variance of a fair die roll\n",
    "variance = np.sum((values - expected_value)**2 * probabilities)\n",
    "print(f\"Variance: {variance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below illustrates the idea of the average of squared errors. Imagine I roll a die 6 times and each time roll a different number. Each blue dot on the plot below represents one roll. The red point/line represents the expecte value for a die roll and the gray number above each point represents the squared distance each point is from the mean. The variance of this dataset is the average of those gray values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a small dataset\n",
    "np.random.seed(0)\n",
    "data = [1,2,3,4,5,6]\n",
    "\n",
    "# Calculate mean and variance\n",
    "data_mean = np.mean(data)\n",
    "data_variance = np.var(data)\n",
    "\n",
    "# Calculate squared errors from the mean\n",
    "squared_errors = (data - data_mean) ** 2\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(data, np.zeros_like(data), color='blue', label='Data Points')\n",
    "plt.scatter(data_mean, 0, color='red', label='Mean', zorder=5)\n",
    "\n",
    "# Lines for deviations\n",
    "for i in range(len(data)):\n",
    "    plt.vlines(data[i], ymin=0, ymax=squared_errors[i], linestyle='--', color='gray', alpha=0.5)\n",
    "    plt.text(data[i], squared_errors[i] + 2, f'{squared_errors[i]:.2f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Highlight the mean\n",
    "plt.vlines(data_mean, ymin=0, ymax=max(squared_errors) + 10, color='red', label='Mean')\n",
    "\n",
    "plt.title('Visualization of Squared Errors')\n",
    "plt.xlabel('Data Value')\n",
    "plt.ylabel('Squared Error from Mean')\n",
    "plt.ylim(0, max(squared_errors) + 20)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean of the data: {data_mean:.2f}\")\n",
    "print(f\"Variance of the data: {data_variance:.2f} (Average of squared errors)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition**: Sample variance is calculated similarly to variance but from sample data. It uses $n−1$ (Bessel's correction) in the denominator to correct bias in the estimation of the population variance from a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Sample variance from random die rolls\n",
    "sample_variance = np.var(sample, ddof=1)  # ddof=1 for unbiased estimator\n",
    "print(f\"Sample Variance: {sample_variance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition**: The standard deviation is the square root of the variance and provides a measure of the spread of data points in the same units as the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Standard deviation of a fair die roll\n",
    "std_deviation = np.sqrt(variance)\n",
    "print(f\"Standard Deviation: {std_deviation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition**: The standard error of the mean (SEM) measures how far the sample mean of the data is likely to be from the true population mean. It's calculated as the standard deviation of the sample divided by the square root of the sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Standard error of the sample mean from random die rolls\n",
    "standard_error = np.std(sample, ddof=1) / np.sqrt(len(sample))\n",
    "print(f\"Standard Error: {standard_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below plots the standard error for rolling dice as sample size increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard error for each sample size\n",
    "standard_errors = [np.std(np.random.choice(values, size=s, p=probabilities), ddof=1) / np.sqrt(s) for s in sample_sizes]\n",
    "\n",
    "# Plotting standard error\n",
    "plt.plot(sample_sizes, standard_errors, label='Standard Error')\n",
    "plt.xlabel('Sample Size')\n",
    "plt.ylabel('Standard Error')\n",
    "plt.title('Standard Error of Sample Means')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCUSSION QUESTION:\n",
    "1. What happens to standard error as sample size increases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Data exploration: distributions\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our recent class, we covered the topics of expected values and variances as ways to describe data. To get a better feel for what these terms mean, we're going to create some example data. This practical exercise will help us understand the implications of these measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's imagine we recorded the flipper lengths of 1000 penguins, measured in centimeters. The code below creates 1000 synthetic data points drawn from a normal distribution given an expected value and variance and prepares two plots for display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to generate data plot and normal distribution plot based on provided mean and variance\n",
    "def plot_syn_data_and_distribution(mean=20, variance=1):\n",
    "    sigma = np.sqrt(variance)  # Standard deviation is the square root of variance\n",
    "    \n",
    "    # Data for the scatter plot\n",
    "    data = np.random.normal(mean, sigma, 100)\n",
    "    \n",
    "    # Data for the normal distribution plot\n",
    "    x = np.linspace(10, 30, 1000)\n",
    "    y = stats.norm.pdf(x, mean, sigma)\n",
    "    \n",
    "    # Setup figure and axes\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Scatter Plot on the first subplot\n",
    "    axs[0].scatter(range(len(data)), data)\n",
    "    axs[0].set_title('Synthetic Flipper Length Data', fontsize=16)\n",
    "    axs[0].set_xlabel('Sample Index', fontsize=14)\n",
    "    axs[0].set_ylabel('Flipper Length (cm)', fontsize=14)\n",
    "    axs[0].set_ylim(10, 30)\n",
    "    axs[0].set_xlim(0, 100)\n",
    "    axs[0].grid(True)\n",
    "    \n",
    "    # Normal Distribution Plot on the second subplot\n",
    "    axs[1].plot(x, y)\n",
    "    axs[1].set_title('Synthetic Flipper Length Data Distribution', fontsize=16)\n",
    "    axs[1].set_xlabel('Flipper Length (cm)', fontsize=14)\n",
    "    axs[1].set_ylabel('Probability Density', fontsize=14)\n",
    "    axs[1].set_xlim(10, 30)\n",
    "    axs[1].set_ylim(0, max(y) + 0.05)\n",
    "    axs[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Custom label for the expected value slider using HTML to ensure visibility\n",
    "expected_value_label = widgets.HTML('<div style=\"width:100px;\">Expected Value:</div>')\n",
    "\n",
    "# Creating the expected value slider without a built-in description\n",
    "expected_value_slider = widgets.FloatSlider(min=10, max=30, step=0.5, value=20, readout_format='.1f', layout=widgets.Layout(width='250px'))\n",
    "\n",
    "# Creating the variance slider with its description\n",
    "variance_slider = widgets.FloatSlider(min=0.5, max=20, step=0.5, value=1, description='Variance:', readout_format='.1f', layout=widgets.Layout(width='320px'))\n",
    "\n",
    "# Grouping the expected value label and slider horizontally\n",
    "expected_value_control = widgets.HBox([expected_value_label, expected_value_slider])\n",
    "\n",
    "# Grouping all controls horizontally\n",
    "controls = widgets.HBox([expected_value_control, variance_slider])\n",
    "\n",
    "# Use interactive widget to link sliders with the plotting function\n",
    "interactive_plot = widgets.interactive_output(plot_syn_data_and_distribution, {'mean': expected_value_slider, 'variance': variance_slider})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below displays both plots.\n",
    "\n",
    "The plot on the left shows 100 data points, with flipper length (in cm) on the y-axis and the sample index on the x-axis. In this scenario, each index corresponds to a different penguin, assuming we measured just one flipper per bird.\n",
    "\n",
    "The plot on the right shows a histogram of all 1000 data points.\n",
    "\n",
    "Below the plots are sliders that allow you to adjust the expected value and the variance of the data. Play around with these sliders and assess how each affects the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(widgets.VBox([interactive_plot, controls]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCUSSION QUESTIONS:\n",
    "1. How does increasing the expected value affect each plot?\n",
    "2. How does decreasing the expected value affect each plot?\n",
    "3. How does increasing the variance affect each plot?\n",
    "4. How does decreasing the variance affect each plot?\n",
    "5. Set the expected value near 20 and the variance near 1. What flipper lengths are you likely to see in this hypothetical penguin population?\n",
    "6. Leave the expected value near 20 and set the variance near 10. What flipper lengths are you likely to see in this hypothetical penguin population? How is this penguin population similar to the hypothetical population from question 5? How is it different from the hypothetical population from questino 5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGNMENT QUESTIONS:\n",
    "- please complete questions 17, 18, and 19 in the canvas assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we record some behavioral data about these penguins. We time the duration each penguin spends underwater during each dive. The code below generates 1000 synthetic datapoints drawn from a uniform distribution and prepares two plots for display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_penguin_data(min_val=0, max_val=10):\n",
    "    # Generating synthetic data\n",
    "    data_100 = np.random.uniform(low=min_val, high=max_val, size=100)\n",
    "    data_1000 = np.random.uniform(low=min_val, high=max_val, size=1000)\n",
    "    \n",
    "    # Calculating mean and variance\n",
    "    mean_val = np.mean(data_1000)\n",
    "    variance_val = np.var(data_1000)\n",
    "    \n",
    "    # Plotting\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Scatter plot for 100 points\n",
    "    axs[0].scatter(range(100), data_100, color='blue')\n",
    "    axs[0].set_title('Synthetic Dive Duration Data', fontsize=16)\n",
    "    axs[0].set_xlabel('Sample Index', fontsize=14)\n",
    "    axs[0].set_ylabel('Dive Duration (min)', fontsize=14)\n",
    "    axs[0].set_ylim(0, 20)  # Fixing y-axis scale\n",
    "    \n",
    "    # Histogram for 1000 points\n",
    "    axs[1].hist(data_1000, bins=30, color='skyblue', edgecolor='black')\n",
    "    axs[1].set_title('Synthetic Dive Duration Data Distribution', fontsize=16)\n",
    "    axs[1].set_xlabel('Dive Duration (min)', fontsize=14)\n",
    "    axs[1].set_ylabel('Frequency', fontsize=14)\n",
    "    axs[1].set_xlim(0, 20)  # Fixing x-axis scale\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Displaying mean and variance\n",
    "    print(f\"Expected Value: {mean_val:.2f}, Variance: {variance_val:.2f}\")\n",
    "\n",
    "# Creating sliders for min and max values\n",
    "min_slider = widgets.FloatSlider(value=0, min=0, max=19.5, step=0.5, description='Min Value:', continuous_update=False)\n",
    "max_slider = widgets.FloatSlider(value=10, min=0.5, max=20, step=0.5, description='Max Value:', continuous_update=False)\n",
    "\n",
    "# Update function to ensure min is always less than max\n",
    "def update_max(*args):\n",
    "    if max_slider.value <= min_slider.value:\n",
    "        min_slider.value = max_slider.value - 0.5\n",
    "def update_min(*args):\n",
    "    if min_slider.value >= max_slider.value:\n",
    "        max_slider.value = min_slider.value + 0.5\n",
    "min_slider.observe(update_max, 'value')\n",
    "max_slider.observe(update_min, 'value')\n",
    "\n",
    "# Using interactive_output to create the plot without automatically displaying sliders\n",
    "interactive_plot = widgets.interactive_output(plot_penguin_data, {'min_val': min_slider, 'max_val': max_slider})\n",
    "\n",
    "# Grouping sliders horizontally\n",
    "controls = widgets.HBox([min_slider, max_slider])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code displays the plots. \n",
    "\n",
    "The left plot shows 100 selected datapoints, with dive duration on the y axis and sample index (or dive instance) on the x axis. \n",
    "\n",
    "The right plot shows a histogram of all 1000 datapoints.\n",
    "\n",
    "The expected value and the variance of the data are printed below the plots.\n",
    "\n",
    "At the bottom of the figure are sliders that allow you to adjust the min and the max value of the data. While a normal distribution is described by an expected value and a variance, a uniform distribution is described by a minimum and a maximum value. When you adjust the sliders, new synthetic data are generated by drawing 1000 new data points from a uniform distribution with your specified minimum and maximum values. Note that the min value slider can not go higher than the max value slider (and vice versa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the plot and controls\n",
    "display(widgets.VBox([interactive_plot, controls]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCUSSION QUESTIONS\n",
    "1. What happens to the variance of the data as the min and max values get farther apart?\n",
    "2. Set the min and max to some value. Change one slider and then change it back again. What happened to the expected value and the variance? Why?\n",
    "3. What happens to the expected value and variance of the data as the min and max values increase but maintain the same distance from each other (i.e. compare min val 0 max val 10 to min val 10 max val 20).\n",
    "4. What are some environmental conditions that could explain why the dive time of these penguins is uniformly distributed?\n",
    "5. What are some environmental conditions that could make it unlikely for dive time to be uniformly distributed?\n",
    "6. What constraints might establish the maximum dive time?\n",
    "8. What constraints might establish the minimum dive time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGNMENT QUESTIONS:\n",
    "- Please complete questions 20 and 21 in the assignment on canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we now want to measure whether each pengin successfully catches a fish with each dive. For each dive we observe, we record a `0` if the penguin resurfaces without a fish and a `1` if the penguin resurfaces with a fish. The code below generates synthetic data drawn from a bernoulli distribution and prepares two plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_penguin_fishing(p=0.5):\n",
    "    # Generating 1000 Bernoulli-distributed points\n",
    "    data = np.random.binomial(1, p, 1000)\n",
    "    \n",
    "    # Expected value and variance for Bernoulli distribution\n",
    "    expected_value = np.mean(data)\n",
    "    variance = np.var(data, ddof=1)\n",
    "    \n",
    "    # Setting up plots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Scatter plot for first 100 points\n",
    "    axs[0].scatter(range(100), data[:100], color='blue')\n",
    "    axs[0].set_title('Outcomes of 100 Dives', fontsize=16)\n",
    "    axs[0].set_xlabel('Sample Index', fontsize=14)\n",
    "    axs[0].set_ylabel('Failure (0) or Success (1)', fontsize=14)\n",
    "    axs[0].set_ylim(-0.1, 1.1)\n",
    "    \n",
    "    # Histogram for all 1000 points\n",
    "    axs[1].hist(data, bins=[-0.5,0.5,1.5], rwidth=0.8, color='skyblue', edgecolor='black', align='mid')\n",
    "    axs[1].set_title('Distribution of Outcomes of All Dives', fontsize=16)\n",
    "    axs[1].set_xlabel('Failure (0) or Success (1)', fontsize=14)\n",
    "    axs[1].set_xticks([0,1])\n",
    "    axs[1].set_ylabel('Frequency', fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Displaying expected value and variance\n",
    "    print(f\"Expected Value: {expected_value:.2f}, Variance: {variance:.2f}\")\n",
    "\n",
    "# Custom label for the probability slider\n",
    "p_slider_label = widgets.HTML('Probability of Success:', layout=widgets.Layout(width='150px'))\n",
    "\n",
    "# Creating the slider without a built-in description\n",
    "p_slider = widgets.FloatSlider(min=0, max=1, step=0.01, value=0.5, readout_format='.2f', layout=widgets.Layout(width='300px'), continuous_update=False)\n",
    "\n",
    "# Grouping the label and slider horizontally\n",
    "p_slider_control = widgets.HBox([p_slider_label, p_slider])\n",
    "\n",
    "# Interactive widget to link slider with the plotting function\n",
    "interactive_plot = widgets.interactive_output(plot_penguin_fishing, {'p': p_slider})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below displays two plots.\n",
    "\n",
    "The left plot shows 100 datapoints with success on the y axis and dive instance on the x axis.\n",
    "\n",
    "The right plot shows the distribution of failure vs success for all dives.\n",
    "\n",
    "The expected values and variances of the generated data are displayed below the plots.\n",
    "\n",
    "A slider below the plots allows you to adjust the probability each penguin is successful. This probability of success is the parameter that describes the bernoulli distribution. When you adjust the slider, new data are drawn from a bernoulli distribution with your specified probability of success and displayed in the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the interactive plot and the custom slider control\n",
    "display(widgets.VBox([interactive_plot, p_slider_control]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCUSSION QUESTIONS:\n",
    "1. How does the probability of success compare to the expected value of the data?\n",
    "2. At what probabilities of success is the variance greatest? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGNMENT QUESTIONS:\n",
    "- Please complete questions 22 and 23 in the assignment on canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose penguins make a specific number of attempts to feed their young each day. Each attempt may be successful or may fail, but the parent penguins never change the number of attempts they make. Suppose we watch 1000 parent penguins for one day and for each penguin, we record the number of feeding attempts that are successful. The code below generates synthetic data drawn from a binomial distribution and prepares two plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_penguin_feeding_attempts(n=10, p=0.7):\n",
    "    # Generating binomial-distributed points for feeding attempts\n",
    "    data = np.random.binomial(n, p, 1000)\n",
    "    \n",
    "    # Expected value and variance for binomial distribution\n",
    "    expected_value = np.mean(data)\n",
    "    variance = np.var(data)\n",
    "    \n",
    "    # Setting up plots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Scatter plot for first 100 points\n",
    "    axs[0].scatter(range(100), data[:100], color='blue')\n",
    "    axs[0].set_title('Successful Feeds for 100 Penguins', fontsize=16)\n",
    "    axs[0].set_xlabel('Penguin ID', fontsize=14)\n",
    "    axs[0].set_ylabel('Number of Successful Feeds', fontsize=14)\n",
    "    axs[0].set_ylim(0, n+1)\n",
    "    \n",
    "    # Histogram for all 1000 points\n",
    "    axs[1].hist(data, bins=range(n+2), align='left', color='skyblue', edgecolor='black')\n",
    "    axs[1].set_title('Distribution of Successful Feeds Over 1000 Days', fontsize=16)\n",
    "    axs[1].set_xlabel('Number of Successful Feeds', fontsize=14)\n",
    "    axs[1].set_ylabel('Frequency', fontsize=14)\n",
    "    axs[1].set_xticks(range(n+1))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Displaying expected value and variance\n",
    "    print(f\"Expected Value: {expected_value:.2f}, Variance: {variance:.2f}\")\n",
    "\n",
    "# Custom label for the number of attempts and success probability sliders\n",
    "n_slider_label = widgets.HTML(value=\"Number of Attempts:\", layout=widgets.Layout(width='140px'))\n",
    "p_slider_label = widgets.HTML(value=\"Probability of Success:\", layout=widgets.Layout(width='160px'))\n",
    "\n",
    "# Creating the sliders without built-in descriptions\n",
    "n_slider = widgets.IntSlider(value=10, min=1, max=20, step=1, layout=widgets.Layout(width='300px'), continuous_update=False)\n",
    "p_slider = widgets.FloatSlider(value=0.7, min=0, max=1, step=0.01, layout=widgets.Layout(width='300px'), continuous_update=False)\n",
    "\n",
    "# Grouping labels and sliders horizontally\n",
    "n_slider_control = widgets.HBox([n_slider_label, n_slider])\n",
    "p_slider_control = widgets.HBox([p_slider_label, p_slider])\n",
    "\n",
    "# Interactive widget to link sliders with the plotting function\n",
    "interactive_plot = widgets.interactive_output(plot_penguin_feeding_attempts, {'n': n_slider, 'p': p_slider})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below displays the plots.\n",
    "\n",
    "The left plot shows data from 100 penguins with number of successful feeds on the y axis and penguin ID on the x axis.\n",
    "\n",
    "The right plot shows a histogram of data for all penguins.\n",
    "\n",
    "The expected value and variance of the data are displayed below the plots.\n",
    "\n",
    "Sliders below the plot allow you to change the probability of penguin success and the number of attempts each penguin will make to feed their young."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the plot and sliders side by side\n",
    "display(widgets.VBox([interactive_plot, widgets.HBox([p_slider_control, n_slider_control])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCUSSION QUESTIONS:\n",
    "1. What happens to the variance as you increase the number of attempts? Why?\n",
    "2. At what probabilities of success is the variance greatest? Why?\n",
    "3. How does the expected value compare to the number of attempts and the probability of success? (Hint: Try setting the probability of success to .5 and varying the number of attempts. How does the expected value compare to the number of attempts? Now set the probability of success to 1 and vary the number of attempts. Do you notice a pattern?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGNMENT QUESTIONS:\n",
    "- Please answer questions 24, 25, 26, and 27 in the assignment on canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets say we are interested in the number of times adult penguins visit their nest within a day. These visits may be for feeding the chicks or maintaining the nest. The number of visits can vary. Suppose we record how many nest visits 1000 penguins make in one day. The poisson distribution gives the probability of an event happening a certain number of times within a given interval of time or space, making it a good choice for modeling these data. The code below generates synthetic data drawn from a Poisson Distribution and prepares two plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_penguin_nest_visits(lam=5):\n",
    "    # Generating Poisson-distributed points for nest visits\n",
    "    data = np.random.poisson(lam, 1000)\n",
    "    \n",
    "    # Expected value and variance for Poisson distribution\n",
    "    expected_value = np.mean(data)\n",
    "    variance = np.var(data)\n",
    "    \n",
    "    # Setting up plots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Scatter plot for first 100 points\n",
    "    axs[0].scatter(range(100), data[:100], color='blue')\n",
    "    axs[0].set_title('Nest Visits for 100 Penguins', fontsize=16)\n",
    "    axs[0].set_xlabel('Penguin Number', fontsize=14)\n",
    "    axs[0].set_ylabel('Number of Nest Visits', fontsize=14)\n",
    "    axs[0].set_ylim(0, max(data[:100]) + 2)\n",
    "    \n",
    "    # Histogram for all 1000 points\n",
    "    axs[1].hist(data, bins=range(min(data), max(data) + 2), align='left', color='skyblue', edgecolor='black')\n",
    "    axs[1].set_title('Distribution of Nest Visits Among 1000 Penguins', fontsize=16)\n",
    "    axs[1].set_xlabel('Number of Nest Visits', fontsize=14)\n",
    "    axs[1].set_ylabel('Frequency', fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Displaying expected value and variance\n",
    "    print(f\"Expected Value: {expected_value}, Variance: {variance}\")\n",
    "\n",
    "# HTML widget for the slider label\n",
    "lam_slider_label = widgets.HTML('Average Visits per day:', layout=widgets.Layout(width='140px'))\n",
    "\n",
    "# Slider for the average number of nest visits (λ) without built-in description\n",
    "lam_slider = widgets.FloatSlider(value=5, min=1, max=10, step=1, layout=widgets.Layout(width='300px'), continuous_update=False)\n",
    "\n",
    "# Grouping the HTML label and slider horizontally\n",
    "lam_slider_control = widgets.HBox([lam_slider_label, lam_slider])\n",
    "\n",
    "# Interactive widget to link slider with the plotting function\n",
    "interactive_plot = widgets.interactive_output(plot_penguin_nest_visits, {'lam': lam_slider})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below displays the plots. \n",
    "\n",
    "On the left is a scatter plot of data for 100 pengiuns from the dataset. \n",
    "\n",
    "On the right is a histogram of the entire dataset.\n",
    "\n",
    "The expected value and the variance of the data are displayed below the plots.\n",
    "\n",
    "A slider below the plots allows you to manimulate the average number of visits made by the penguins each day across the dataset. The mean number of events observed is the parameter that describes the Poisson distribution. Note that the x-axis rescales on the histogram as the average visits slider is moved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the plot and custom slider control\n",
    "display(widgets.VBox([interactive_plot, lam_slider_control]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCUSSION QUESTIONS:\n",
    "\n",
    "1. How does the expected value of the data compare to the average number of nest visits?\n",
    "2. How does increasing the average number of visits affect the variance? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGNMENT QUESTIONS:\n",
    "- Please answer question 28 in the assignment on canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we are now observing the timing of penguin egg hatching. We're interested in the time between successive hatching events across the colony. This time interval can vary significantly and is influenced by numerous factors, but each hatching event occurs independently of others. The exponential distribution is ideal for modeling the time between these events. The code below generates synthetic data by drawing fron an exponential distribution and prepares two plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hatching_intervals(lam=3):\n",
    "    # Generating exponential-distributed points for hatching intervals\n",
    "    data = np.random.exponential(1/lam, 1000)\n",
    "    \n",
    "    # Expected value and variance for Exponential distribution\n",
    "    expected_value = np.mean(data)\n",
    "    variance = np.var(data)\n",
    "    \n",
    "    # Setting up plots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Determine max value for consistent axis limit\n",
    "    max_val = max(data) + 0.5  # Adding a buffer to the maximum value for better visualization\n",
    "    \n",
    "    # Scatter plot for first 100 points\n",
    "    axs[0].scatter(range(100), data[:100], color='blue')\n",
    "    axs[0].set_title('Time Between First 100 Hatching Events', fontsize=16)\n",
    "    axs[0].set_xlabel('Hatching Event Number', fontsize=14)\n",
    "    axs[0].set_ylabel('Time Between Events (days)', fontsize=14)\n",
    "    axs[0].set_ylim(0, max_val)  # Setting y-axis limit based on max_val\n",
    "    \n",
    "    # Histogram for all 1000 points\n",
    "    axs[1].hist(data, bins=30, color='skyblue', edgecolor='black')\n",
    "    axs[1].set_title('Distribution of Time Between Hatching Events', fontsize=16)\n",
    "    axs[1].set_xlabel('Time Between Events (days)', fontsize=14)\n",
    "    axs[1].set_ylabel('Frequency', fontsize=14)\n",
    "    axs[1].set_xlim(0, 10)  # Setting x-axis limit based on max_val\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Displaying expected value and variance\n",
    "    print(f\"Expected Value: {expected_value:.2f} days, Standard Deviation: {np.sqrt(variance):.2f} days\")\n",
    "\n",
    "# HTML widget for the rate parameter (λ) slider label\n",
    "lam_slider_label = widgets.HTML('Average Hatching Events per Day (λ):', layout=widgets.Layout(width='190px'))\n",
    "\n",
    "# Slider for the rate parameter (λ) without built-in description\n",
    "lam_slider = widgets.FloatSlider(value=3, min=0.1, max=10, step=0.1, layout=widgets.Layout(width='300px'), continuous_update=False)\n",
    "\n",
    "# Grouping the HTML label and slider horizontally\n",
    "lam_slider_control = widgets.HBox([lam_slider_label, lam_slider])\n",
    "\n",
    "# Interactive widget to link slider with the plotting function\n",
    "interactive_plot = widgets.interactive_output(plot_hatching_intervals, {'lam': lam_slider})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below displays both plots.\n",
    "\n",
    "The left plot shows a scatter plot of data from 100 penguins in the dataset.\n",
    "\n",
    "The right plot shows a histogram of all data in the dataset.\n",
    "\n",
    "The expected value and the standard deviation of the data are displayed below the plots. Note that the standard deviation is the square root of the variance. The standard deviation is also a measure of dispearsal around the mean. In this case the standard deviation is shown instead of the variance because the units for variance here would be days squared. To keep the units simple, we take the square root of the variance and display the standard deviation in units of days.\n",
    "\n",
    "Below the plots is a slider that lets you adjust the average rate of hatching in units of hatching events per day. This rate of occurance (referred to as $\\lambda$) is the parameter that describes an exponential distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the plot and custom slider control\n",
    "display(widgets.VBox([interactive_plot, lam_slider_control]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCUSSION QUESTIONS:\n",
    "1. As you increase $\\lambda$, what happens to the distribution of time between hatching events? What happens as you decrease lambda?\n",
    "2. As you increase $\\lambda$, what happens to the standard deviation of time between hatching events? What happens as you decrease lambda?\n",
    "3. As you decrease the rate of hatching events per day, what happens to the expected value? What does the expected value describe for these data?\n",
    "4. For what values of $\\lambda$ are the most chicks hatching?\n",
    "5. How are the exponential and poisson distributions different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGNMENT QUESTIONS:\n",
    "- Please answer questions 29 and 30 on canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data transformation is an important preprocessing step used in data analysis to modify original data into a new format or structure. It can be applied for a variety of reasons including improving the interpretability of data, meeting the assumptions of statistical methods, and/or improving the performance of predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear transformations scale or shift data:\n",
    "- Scaling a distribution: scaling involves multiplying data by a constant.\n",
    "- Shifting a distribution: shifting involves adding a constant to all data points.\n",
    "\n",
    "The code below prepares two plots for you to explore this concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scaled_distribution(scale=1.0):\n",
    "    # Original data\n",
    "    np.random.seed(0)\n",
    "    data = np.random.randn(1000)  # Standard normal distribution\n",
    "    \n",
    "    # Scaled data\n",
    "    scaled_data = data * scale\n",
    "    \n",
    "    # Calculate mean and variance of the scaled data\n",
    "    mean_scaled = np.mean(scaled_data)\n",
    "    variance_scaled = np.var(scaled_data)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.hist(scaled_data, bins=30, alpha=0.7, color='skyblue')\n",
    "    plt.title(f'Scaled Distribution\\nScale Factor = {scale}\\nMean = {mean_scaled:.2f}, Variance = {variance_scaled:.2f}')\n",
    "    plt.xlim([-10, 10])\n",
    "    plt.show()\n",
    "\n",
    "def plot_shifted_distribution(shift=0.0):\n",
    "    # Original data\n",
    "    np.random.seed(0)\n",
    "    data = np.random.randn(1000)  # Standard normal distribution\n",
    "    \n",
    "    # Shifted data\n",
    "    shifted_data = data + shift\n",
    "    \n",
    "    # Calculate mean and variance of the shifted data\n",
    "    mean_shifted = np.mean(shifted_data)\n",
    "    variance_shifted = np.var(shifted_data)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.hist(shifted_data, bins=30, alpha=0.7, color='lightgreen')\n",
    "    plt.title(f'Shifted Distribution\\nShift = {shift}\\nMean = {mean_shifted:.2f}, Variance = {variance_shifted:.2f}')\n",
    "    plt.xlim([-10, 10])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Interactive widgets\n",
    "scale_slider = widgets.FloatSlider(value=1.0, min=0.1, max=5.0, step=0.1, description='Scale:')\n",
    "shift_slider = widgets.FloatSlider(value=0.0, min=-5.0, max=5.0, step=0.1, description='Shift:')\n",
    "\n",
    "# Use interactive widget to link sliders with the plotting functions\n",
    "interactive_scaled_plot = widgets.interactive(plot_scaled_distribution, scale=scale_slider)\n",
    "interactive_shifted_plot = widgets.interactive(plot_shifted_distribution, shift=shift_slider)\n",
    "\n",
    "# Construct VBox with interactive widgets\n",
    "scale_box = widgets.VBox([interactive_scaled_plot])\n",
    "shift_box = widgets.VBox([interactive_shifted_plot])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will display two normal distributions. You can scale the normal distribution on the left by adjusting the scale factor with the slide "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the layouts\n",
    "display(widgets.HBox([scale_box, shift_box]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCUSSION QUESTIONS:\n",
    "1. What happens to the distribution mean as the distribution is scaled?\n",
    "2. What happens to the distribution variance as the distribution is scaled?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nonlinear transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonlinear transformations modify data in ways that are not uniform across all values. Common examples include:\n",
    "\n",
    "- Logarithmic Transformation: Applying the logarithm to data can help reduce skewness, especially for data that span several orders of magnitude. It's particularly useful for making exponential growth patterns more linear and for handling positively skewed data.\n",
    "\n",
    "- Squaring Transformation: Squaring data amplifies larger values more than smaller ones, which can be useful for datasets where the variance increases with the mean. However, it also increases skewness and can make distributions more skewed to the right.\n",
    "\n",
    "These transformations can change the relationship between variables, often making it easier to model with linear techniques or to meet the assumptions of various statistical tests. The code below prepares two plots for you to explore these ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_log_transformed_distribution(log_transform=False, add_constant=1e-6):\n",
    "    np.random.seed(0)\n",
    "    # Use an exponential distribution as the starting point\n",
    "    data = np.random.exponential(scale=1, size=1000)  # Exponential distribution\n",
    "    \n",
    "    if log_transform:\n",
    "        # Apply logarithmic transformation, adding a small constant to avoid log(0)\n",
    "        transformed_data = np.log(data + add_constant)\n",
    "        color = 'orange'\n",
    "        title = 'Log-Transformed Distribution'\n",
    "    else:\n",
    "        # Use the original exponential data\n",
    "        transformed_data = data\n",
    "        color = 'skyblue'\n",
    "        title = 'Original Exponential Distribution'\n",
    "    \n",
    "    # Calculate mean and variance\n",
    "    mean_transformed = np.mean(transformed_data)\n",
    "    variance_transformed = np.var(transformed_data)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.hist(transformed_data, bins=30, color=color)\n",
    "    plt.title(f'{title}\\nMean = {mean_transformed:.2f}, Variance = {variance_transformed:.2f}')\n",
    "    plt.show()\n",
    "\n",
    "def plot_squared_distribution(square=False):\n",
    "    np.random.seed(0)\n",
    "    # Use a standard normal distribution as the starting point\n",
    "    data = np.random.randn(1000)  # Standard normal distribution\n",
    "    \n",
    "    if square:\n",
    "        # Apply squaring transformation\n",
    "        transformed_data = np.square(data)\n",
    "        color = 'purple'\n",
    "        title = 'Squared Distribution'\n",
    "    else:\n",
    "        # Use the original normal data\n",
    "        transformed_data = data\n",
    "        color = 'lightgreen'\n",
    "        title = 'Original Normal Distribution'\n",
    "    \n",
    "    # Calculate mean and variance\n",
    "    mean_transformed = np.mean(transformed_data)\n",
    "    variance_transformed = np.var(transformed_data)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.hist(transformed_data, bins=30, color=color)\n",
    "    plt.title(f'{title}\\nMean = {mean_transformed:.2f}, Variance = {variance_transformed:.2f}')\n",
    "    plt.show()\n",
    "\n",
    "# Interactive widgets\n",
    "log_transform_toggle = widgets.Checkbox(value=False, description='Log Transform')\n",
    "square_toggle = widgets.Checkbox(value=False, description='Square Data')\n",
    "\n",
    "# Interactive plots\n",
    "interactive_log_plot = widgets.interactive(plot_log_transformed_distribution, log_transform=log_transform_toggle, add_constant=widgets.FloatSlider(value=1e-6, min=1e-6, max=1e-2, step=1e-6, description='Constant:', readout_format='.1e'))\n",
    "interactive_squared_plot = widgets.interactive(plot_squared_distribution, square=square_toggle)\n",
    "\n",
    "# Layout\n",
    "log_transform_box = widgets.VBox([log_transform_toggle, interactive_log_plot.children[-1]])  # .children[-1] to only display the output\n",
    "squared_transform_box = widgets.VBox([square_toggle, interactive_squared_plot.children[-1]])  # .children[-1] to only display the output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below displays the plots. The checkboxes above each plot allow you to log transform or square the data respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(widgets.HBox([log_transform_box, squared_transform_box]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCUSSION QUESTIONS:\n",
    "1. The left plot begins as an exponential distribution. What happens when you log transform those data? What distribution does the data resemble?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Data exploration: correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spearman vs Pearson Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets say we now have genetic information about these penguins over 20 generations. We want to track the frequency of allele \"A\" in the population over time. The code below generates synthetic data tracking the frequency of this allele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "# Parameters\n",
    "initial_frequency = 0.01  # Initial frequency of the allele\n",
    "r = 0.15  # Rate of increase\n",
    "generations = np.arange(1, 21)  # 20 generations\n",
    "noise_strength = 0.005\n",
    "\n",
    "# Exponential growth of the allele frequency\n",
    "allele_frequencies = initial_frequency * np.exp(r * generations)\n",
    "allele_frequencies_noisy = allele_frequencies + np.random.normal(0, noise_strength, size=generations.shape)\n",
    "# Ensure frequencies are within [0.1, 1]\n",
    "allele_frequencies_noisy = np.clip(allele_frequencies_noisy, 0.01, 1)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(generations, allele_frequencies_noisy, marker='o', linestyle='-', color='blue')\n",
    "plt.title('Allele A Frequency Over Generations')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Allele A Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Calculate Pearson and Spearman correlations\n",
    "pearson_corr, _ = scipy.stats.pearsonr(generations, allele_frequencies)\n",
    "spearman_corr, _ = scipy.stats.spearmanr(generations, allele_frequencies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCUSSION QUESTION:\n",
    "1. For these data, which will be greater, the pearson or the spearman correlation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we also track the frequency of a allele \"B\" in the population. The code below generates and plots data for allele \"B\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_frequency = 0.01  # Initial frequency of the allele\n",
    "r = 0.3  # Rate of increase\n",
    "generations = np.arange(1, 21)  # 20 generations\n",
    "noise_strength = 0.08\n",
    "\n",
    "# Exponential growth of the allele frequency\n",
    "allele_frequencies = initial_frequency * np.exp(r * generations)\n",
    "allele_frequencies_noisy = allele_frequencies + np.random.normal(0, noise_strength, size=generations.shape)\n",
    "# Ensure frequencies are within [0.1, 1]\n",
    "allele_frequencies_noisy = np.clip(allele_frequencies_noisy, 0.01, 1)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(generations, allele_frequencies_noisy, marker='o', linestyle='-', color='blue')\n",
    "plt.title('Allele B Frequency Over Generations')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Allele Frequency')\n",
    "plt.ylim(0, 1)  # Limit y-axis to 1 for visualization purposes\n",
    "plt.show()\n",
    "\n",
    "# Calculate Pearson and Spearman correlations\n",
    "pearson_corr, _ = scipy.stats.pearsonr(generations, allele_frequencies)\n",
    "spearman_corr, _ = scipy.stats.spearmanr(generations, allele_frequencies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCUSSION QUESTION:\n",
    "1. Compare the plots of Allele A frequency and Allele B frequency. Which will have a higher pearson correlation coefficient? Which will have a higher spearman correlation coefficient? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we track a third allele, allele C, and plot its frequency in the population over 20 generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating fluctuating allele frequencies\n",
    "np.random.seed(42)  # For reproducibility\n",
    "generations = np.arange(1, 21)  # 20 generations\n",
    "allele_frequencies = np.abs(np.sin(np.linspace(0, 3 * np.pi, 20)) + np.random.normal(0, 0.1, 20))\n",
    "noise_strength = 0.08\n",
    "\n",
    "# Ensure frequencies are within [0, 1]\n",
    "allele_frequencies = np.clip(allele_frequencies, 0, 1)\n",
    "allele_frequencies_noisy = allele_frequencies + np.random.normal(0, noise_strength, size=generations.shape)\n",
    "# Ensure frequencies are within [0.1, 1]\n",
    "allele_frequencies_noisy = np.clip(allele_frequencies_noisy, 0.01, 1)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(generations, allele_frequencies_noisy, marker='o', linestyle='-', color='blue')\n",
    "plt.title('Allele C Frequency Over Generations')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Allele Frequency')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# Calculate Pearson and Spearman correlations\n",
    "pearson_corr, _ = stats.pearsonr(generations, allele_frequencies)\n",
    "spearman_corr, _ = stats.spearmanr(generations, allele_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCUSSION QUESTIONS:\n",
    "1. How will the pearson correlation coefficient of the allele c data compare to the pearson correlation coefficients of alleles a and b?\n",
    "2. How will the spearman correlation coefficient of the allele c data compare to the spearman correlation coefficients of alleles a and b?\n",
    "3. Based on these data, which of these alleles is/are most likely to confer a fitness advantage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Penguin Data!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have exciting news! A team of researchers did collect a bunch of data about penguins! The [Palmer Penguin dataset](https://allisonhorst.github.io/palmerpenguins/) was collected by [Dr. Kristen Gorman](https://www.uaf.edu/cfos/people/faculty/detail/kristen-gorman.php) at the [Palmer Research Station](https://pallter.marine.rutgers.edu/) in Antarctica. The dataset is commonly used for teaching data analysis techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below imports the data into a dataframe and displays the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to the raw CSV file on GitHub\n",
    "url = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\"\n",
    "\n",
    "# Use Pandas to read the CSV file directly from the URL\n",
    "penguins_df = pd.read_csv(url)\n",
    "\n",
    "# Print dimensions of the dataframe\n",
    "print(penguins_df.shape)\n",
    "\n",
    "penguins_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the dataset includes observations of 3444 penguins. For each penguin, 8 different features are recorded (species, island, bill length, bill depth, flipper length, body mass, sex, and year)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how bill length compares to flipper length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values to simplify this example\n",
    "penguins_cleaned = penguins_df.dropna(subset=['bill_length_mm', 'flipper_length_mm'])\n",
    "\n",
    "# Select two continuous variables\n",
    "body_mass = penguins_cleaned['body_mass_g']\n",
    "flipper_length = penguins_cleaned['flipper_length_mm']\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(body_mass, flipper_length, color='blue')\n",
    "\n",
    "plt.title('Body Mass vs. Flipper Length')\n",
    "plt.xlabel('Body Mass (g)')\n",
    "plt.ylabel('Flipper Length (mm)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCUSSION QUESTIONS: For a hint run the cell below.\n",
    "1. Given what we learned in class about pearson correlation, what do you expect the pearson correlation of these data to be (describe qualitatively, i.e. high, low, medium low, ect). Why?\n",
    "2. Given what we learned in class about spearman correlation, what do you expect the spearman correlation of these data to be (describe qualitatively, i.e. high, low, medium low, ect). Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the line of best fit\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(body_mass, flipper_length)\n",
    "line = slope * body_mass + intercept\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(body_mass, flipper_length, label='Data points')\n",
    "\n",
    "# Plot the line of best fit\n",
    "plt.plot(body_mass, line, color='red', label=f'Line of best fit: y={slope:.2f}x+{intercept:.2f}')\n",
    "\n",
    "plt.title('Body Mass vs. Flipper Length with Line of Best Fit')\n",
    "plt.xlabel('Body Mass (g)')\n",
    "plt.ylabel('Flipper Length (mm)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below calculates the pearson and spearman correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pearson's correlation\n",
    "pearson_corr, _ = stats.pearsonr(body_mass, flipper_length)\n",
    "print(f\"Pearson's correlation: {pearson_corr:.3f}\")\n",
    "\n",
    "# Calculate Spearman's correlation\n",
    "spearman_corr, _ = stats.spearmanr(body_mass, flipper_length)\n",
    "print(f\"Spearman's correlation: {spearman_corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCUSSION QUESTION:\n",
    "1. How do these values compare to your predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the penguins dataset! Try plotting different continuous penguin features against each other by editing the code below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the set of continuous feature titles available in the palmer penguins dataset\n",
    "[\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
    "\n",
    "# Select two continuous variables by assigning their string titles to the variables feature1 and feature2\n",
    "feature1 = \"bill_length_mm\"\n",
    "feature2 = \"flipper_length_mm\"\n",
    "\n",
    "# Drop rows with missing values\n",
    "penguins_cleaned = penguins_df.dropna(subset=[feature1, feature2])\n",
    "\n",
    "# Select two continuous variables\n",
    "x_axis = penguins_cleaned[feature1]\n",
    "y_axis = penguins_cleaned[feature2]\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_axis, y_axis, color='blue')\n",
    "\n",
    "plt.title(f'{feature1} vs. {feature2}')\n",
    "plt.xlabel(f'{feature1}')\n",
    "plt.ylabel(f'{feature2}')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Calculate Pearson's correlation\n",
    "pearson_corr, _ = stats.pearsonr(x_axis, y_axis)\n",
    "print(f\"Pearson's correlation: {pearson_corr:.3f}\")\n",
    "\n",
    "# Calculate Spearman's correlation\n",
    "spearman_corr, _ = stats.spearmanr(x_axis, y_axis)\n",
    "print(f\"Spearman's correlation: {spearman_corr:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biol359",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
